# Sprint 2 Hackathon

It's time for the second hackathon - 8 hours of independent data crunching and analysis! It's a chance to put everything you've learnt over the past sprint into practice, experience the realities of data science, and test out new ideas in a experimental environment.  

### Task

You will be provided with several datasets from different sources that cover a range of topics. Some data might be specific to your cohort/company, while other data will be completely unfamiliar. You are also welcome to bring your own data that you would like to analyse if your organisation's data sharing rules permit that.

In the time provided, create a model based on supervised learning to predict some aspect of one of the datasets. You are free to choose the dataset, aspect, and method that most interest you; you can even combine multiple datasets if you wish.

### Guidelines

* It's a good idea to explore the data available early on; having a strong understanding of a dataset's structure and contents will be invaluable for modelling
* All the datasets will need some level of data cleaning before modelling can begin. Some will be much cleaner than others
* It's best to work in pairs/small groups
* A hackathon isn't about creating a finished, polished product; it's about learning, exploring, and collaborating together

### Resources

* [Classification vs. Regression](https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/)

|Python | R |
|---|---|
| [Python docs](https://docs.python.org/3/)|[R docs](https://www.r-project.org/other-docs.html) |
| [Data cleaning with Pandas & Numpy](https://realpython.com/python-data-cleaning-numpy-pandas/) |[An Introduction to data cleaning with R](https://cran.r-project.org/doc/contrib/de_Jonge+van_der_Loo-Introduction_to_data_cleaning_with_R.pdf) |
| [Pandas docs](https://pandas.pydata.org/pandas-docs/stable/)||

### Datasets
We have carefully chosen datasets that allow you to practice the skills covered in Sprint 2. While the data used in the hackathons might not always be directly relevant to your day-to-day work, the skills, experience, and ideas you garner from working with them will have wider applications. You can find links to these datasets below:

* [NYC property sales](https://www.kaggle.com/new-york-city/nyc-property-sales)
* [Election campaign finance](https://www.kaggle.com/danerbland/electionfinance)
* [Men's shoe prices](https://www.kaggle.com/datafiniti/mens-shoe-prices)
* [Women's shoe prices](https://www.kaggle.com/datafiniti/womens-shoes-prices)
* [Rain in Australia](https://www.kaggle.com/jsphyg/weather-dataset-rattle-package)
* [Bank Customers dataset](https://www.kaggle.com/santoshd3/bank-customers) (finance)
* [Default of Credit Card Clients dataset](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset) (finance)
* [S&P 500 Stock datasets](https://github.com/DecodedCo/data-fellowship/blob/master/modules/hackathons/hackathon-2.md) (finance)
* [Bank Failures dataset](https://www.kaggle.com/dany17/national-and-state-bank-failures) (finance)
* [Chase Bank Deposits dataset](https://www.kaggle.com/chasebank/bank-deposits) (finance)
* [Other finance/economics related datasets](https://blog.cambridgespark.com/50-free-machine-learning-datasets-part-two-financial-and-economic-datasets-6620274ee593)
